Microsoft Build May 19-22, 2025 Session: BRK163 Speakers: Gaurave Sehgal, Matt Barbour, Renil Abdulkader, Sarah Critchley

Sarah Critchley: Good morning, everyone here in Seattle, and also for those watching online. First of all, I just want to say thank you so much for just choosing to be with us here today with your focus and attention. I'm Sarah Critchley, Principal Product Manager for the Microsoft 365 Agents SDK. I'm joined on stage by --

Matt Barbour: My name is Matt Barbour. I wear a couple of hats at Microsoft. I'm a principal architect for the developer platform, and I also am the Development Manager for the Agents SDK.

Sarah Critchley: No surprise, we're here to talk to you about agents today. You heard in the keynotes and you've heard from other various leaders across the last few days how amazing the last few years have been. Like, truly amazing, and I think it's always good to just take stock, or take a beat, and just think about that and how exciting it is. Because we have had a fundamental shift in technology. And that shift is the fact that it's normal now to use conversation and questions and natural language to interact with technology. It's becoming normal for us. Despite the technology itself not being completely new. I can pick up my phone, open a banking app, and I'll be greeted by an agent. The agent is going to say, hey, what can I do for you? That agent is going to be grounded on my data. It's going to be combined with all of the services that the bank provides, the culture, how that bank wants to communicate with me, and I'm going to ask it a question. And I'm going to get a response that's specific to me. I'm not just going to get some canned response anymore. I'm going to get a response that's very specific to me because it's grounded in my data but then also in the way that the bank wants to communicate with me. In the same way that if you, or you, or you was to ask the very same question, you would actually get something different because it would be grounded in your data. I can go to my Microsoft laptop, I can go to our AskHR agent, and I can ask a question about my travel grounded on my data, specific for me. I can go to a website, put a tracking code in, and it won't just tell me where my parcel is anymore. It will say, well, Sarah, what do you want to do about it? Don't worry. We've got this. Do you want to rearrange a delivery? You just have to click a button. My life is easier. Why is it easier? It isn't just because I'm getting information faster. Easier. My life is better because agents are giving me focus. Agents are actually accessing information on my behalf with the security that I choose to give it with the permissions that I choose to give the agents I interact with. Agents are driving towards a resolution and not just a single task. They don't just come into your day and say, cool, I'm done, see you later. They'll say

anything else. They'll drive to an actual outcome for you. Right at your fingertips, where you're at, whenever you want them. And so how can you all in the audience today and those watching build agents that do this, that help make people's lives easier? Because also it's about actually building agents that don't just do that but also for you all when you're in build mode, when you actually want to create them. What we're interested in providing you is technology that also helps you adapt to the pace of change that we're seeing. We want you to be able to help. We want you to be able to build agents that evolve as this technology evolves as well. At the end of the day, I understand and we understand that you want value, choice, and flexibility. When we work with customers, just like all of you, you want to be able to use the AI that's already been approved by your company's leadership. You want to be able to use your orchestrator that you're already familiar with, that you've already trained your developers on. You want to be able to bring the knowledge that is around your entire enterprise. You want to host your own code so you can lift it and move it wherever you want. You want to deploy it to the channels and the surface areas where your users and customers are. And you know that the best. And also you want to be able to interact with other agents that the enterprise and your company are building. And this is exactly what the Microsoft 365 Agents SDK addresses and focuses on. The Microsoft 365 Agents SDK is an open-source SDK from Microsoft available in C#, JavaScript, and Python. It allows you to bring whatever AI model or AI services that you want to use, whatever orchestrator you want to use with that model, and whatever knowledge you require to ground your requests. You can package that all up inside an agent made with the Agents SDK. And you can use the conversation management capabilities within the SDK, things like managing state, using storage, authentication. And it helps you deploy it to where your customers or your users are. Do you want to be able to use Semantic Kernel with Azure AI Foundry and deploy that to Microsoft 365 Copilot? No sweat. We're going to show you that today. Do you want to use OpenAI agents? No sweat. We're going to show you that today as well. And what is facilitating the Agents SDK is the Microsoft 365 Agents Toolkit. The Agents Toolkit makes interacting with the SDK easy, simple, and a joy to use. And it starts from File, New. We've got built-in templates that you can get started easily from Empty Agent, which allows you to just bring whatever you want, start with the basic scaffolding, and go, to our weather agent that allows you to start with Semantic Kernel or LangChain, or OpenAI and Azure AI Foundry. You just need to throw in a few details, and it's already scaffolded up for you. But it doesn't stop there. You can also go ahead and actually test with the Agents Playground that's embedded in the Toolkit as well. And that allows you to literally just set the debug target and go. And you have a local tool that you can immediately see your AI orchestrator and knowledge coming together and actually working and testing it before you then push to your actual channel. But it also doesn't stop there. It actually helps you also publish to your target channel like Teams or M365 Copilot so you can start to do much deeper integration testing too. And it'll also help you on the final leg of your journey with the deployment process. So we're really trying to not just help get you started with the SDK but actually cover that end-to-end deployment and process so you can actually bring all of your components that you want to use together and actually get it to where you want it to go. So

let's see this in action. So we're going to show some kind of how to get started in our first demo segment. How to get started with the SDK and the toolkit. Over to you, Matt.

Matt Barbour: All righty. Okay. So who's tired of PowerPoint? I am. I get really overwhelmed with PowerPoint at these conferences, especially when it's a developer conference. And I did promise yesterday that we were going to be looking at code. So if you're not comfortable with code and you like WYSIWYG, this is not the session for you. We're going to be talking all about the code, how to do this, how this works, and how to put it together. I'm going to also start with saying that everything I'm going to show you here, you can do now from the existing published libraries. Okay? I'm not going to do anything that is preview. Or if I use something that's preview, I'm going to tell you it's preview. Okay? So first, let's start with this piece of code here. Now, this is a Semantic Kernel sample. In this case, I've enhanced this sample a little bit. It's a Semantic Kernel sample that is supposed to talk to the weather. In this case, I've enhanced it with the OpenWeather API, the free service that just reads some weather. Okay. This is intended to introduce you to Semantic Kernel. You can go find this sample on the web underneath the Semantic Kernel samples. Same sort of thing that you'd see if you were to go beyond the marketing flash for OpenAI or Anthropic or anything of that nature and you actually try to make their code work. You find a little Python library or you find a little.NET library that you have to compile and run, provided some keys. I'm going to just go ahead and run this, show you what it does. So in this case, I've rewired this a little bit in the fact that instead of running this as just an API, I've stuck it inside a console so that it reacts to a console client, and it shows me information about a console. You guys have all seen these, I assume. I can just ask the question. So I've asked it a question about weather in Seattle. Now, there in the background, you see it running. It's doing some communication. It's giving you some status. I'm looking for current weather. I'm getting some data, and I throw back. I've adapted it to throw an adaptive card. I've given it a set of instructions that say, create an adaptive card. Now, OpenAI did that. I didn't build an adaptive card wrapper for this. I just asked OpenAI to give me an adaptive card. Basic Semantic Kernel demonstration. It's awesome it works in a client. Now, how do I make this show up in Teams? How do I make it show up in WebChat? How do I make it show up in BizChat? Okay. This is where the Agent SDK comes into play. Okay. The Agent SDK is not here to tell you to use Semantic Kernel. It is here to facilitate your ability to communicate across the Microsoft ecosystem and beyond and manage the various kinds of orchestrators, AI services, or agent services, as we now call them, that are available in both our ecosystem and in other ecosystems, and supply them and supply visibility to them. So let's just go ahead and close this off, and I'm going to change gears a little bit here. I'm going to pop open Visual Studio. And you guys, if you do the labs, there is a lab where we describe it as, I believe it is Create a Custom Engine Agent with M365 Agent SDK. You'll recognize these steps from that lab. If you haven't done the lab, there's an instance of this a little bit later today. You go through the process of creating a new agent. We'll click the "Create" button. We'll create a project. And I can start with a bunch of templates, or I can pop down here and just choose the basic Echo Agent, which is very much to its name. It's intended to

provide whatever you put in, whatever you put out. It's there to test what we call dial tone. Can it communicate? Okay. This boots up a client. I'm going to compress this because that isn't relevant to our conversation. We're going to look at the program. And within the program file, we're going to see where we're adding a thing called "Cloud Adapter," and we're adding a thing called "Memory Storage" and a thing we're called "Agent Applications." And then we add an agent. Okay. By adding this and then invoking it, just an F5 experience at this point, I haven't deployed this anywhere. I haven't sent this anywhere. I now have an agent that will boot up using the Agent Toolkit and bring up a test experience here if I tag it this way and then tag it that way and then drag this window down here. And say hi there. The Agent SDK provides some basic capabilities, in fact, a lot of capabilities, based on a concept we call the activity protocol. It's our version of really what Google is talking about now, A2A. We've had it for years and years, those of you that are familiar with the bot framework. We just don't wave our flags about it because it's just kind of natural to our infrastructure at this point, the way we communicate between things, sort of like HTTP. In this case, we have a set of events, capabilities, that trigger between clients. So in this case, the test shell, this shell here where my mouse is swinging around, is a thing called the Teams Playground, or the Agent Playground I believe is the new name for it. The Agent Playground is replacing what we used to call the bot framework emulator. Okay. This capability allows us then to interact with an agent locally that we're running within our infrastructure. I didn't stand up dev tunnels. I didn't stand up anything externally. I'm all working within my local loop. Okay. That's awesome. I like that. I know that my agent is working. Because we're under a time pressure, I'm going to collapse this, and I'm going to open up this project here where I've already merged in the Semantic Kernel demo. I'm going to flip back and forth between them for a moment. You'll notice here that there is an agents folder with the weather forecast agent, the weather agent response, the adaptive card plugin, the daytime plugin, the weather forecast plugin. I'm going to switch back over here to my Semantic Kernel demo. There's the same files. This is the Semantic Kernel demo exactly. I have picked it up, and I have dropped it into my Agent SDK project. I have a echobot, which is what I got from my bootstrap project. And I come back over here to my program. And what did I change in my program? What I changed in my program is I added from the sample that Semantic Kernel gave me, the Semantic Kernel Services. Now, how do I wire the user experience that you saw in that command line together? To do that, I come to my echobot agent. And here at the top, I have my constructor. Those of you that are familiar with the legacy bot framework, this is going to look really alien to you. We've moved away from the concept of an activity handler with an override and event concept because the intent is, with the Agent SDK, that we can support any channel, any set of orchestrators within the same agent without having to have you create bespoke copies to deal with these things. So the ability to deal with channels, specific channel capabilities, is now handled through a concept we call extensions. And those things that are shared from a common sense are collapsed into the core Agent SDK itself. Now, everything I'm doing right now, adaptive cards, general communication, what you'll see here in a moment, streaming, is all part of the core. These are core capabilities of the Agent SDK. If I want to use message

extensions or I want to use tabs or something of that nature, which are very Teams-specific constructs, you would use the Teams extension to extend and access those capabilities. And that Teams extension brings the necessary events and hooks for you then to connect to, interact with. So in this case, what I'm doing here is I am catching the conversation. I've received a conversation update specifically of members added, and I want to do something. So I've set up an event handler that says, when that happens, call this method. When I get an activity of type message, call this method. Well, in my case, what I want to do is I want to capture the question to send to the weather agent that I implemented with Semantic Kernel, so I come down here and take a look. Now, there's some ifdef here. We'll talk about that in just a second. What I'm doing here is I'm taking advantage of Semantic Kernel's capability and its behavior of the way it spins off and deals with plugins. So I need to be able to have a plugin actually provide status back to me, to my agent. Something is going on down deep inside Semantic Kernel. Something has occurred. I need to provide status back. So in the Semantic Kernel sample, what did we do? We pushed out something to the console, and we said, hey, this is happening in the console. What I'm doing here is I'm pushing it back out to the agent itself. So I'm going to go ahead and click the "Start" button. We'll boot up. Just a second. Let me get this all the way through. For questions, I've been told to hold them to the end. Zoom in. Okay, got it. So let me do this. Okay. So now I'm going to ask that same question. Oh, we're not quite booted up yet. Refresh there. There we are. Now we're awake. What's the weather there? Okay. So now we're again seeing that same concept bouncing back and forth here, and we've now gotten that adaptive card in the Teams client. Now, that's cool. Let's go take a look a little bit further. I'm going to come out here into Teams. Same question. Well, if I can spell it right, Seattle. Grab that. Drag it across to the right. Pop it in here. There we go. And let's actually spell it right. It'll figure it out. Now, look at that. It figured it out. I'm in Teams now, by the way. This is actually Teams, and it's communicating. And it's bouncing around, and it gave me my card back. Okay. Now, what about here? I'm going to go into my agent builder demo inside M365 -- -- and again, we send it through. Again, our agent on the left is operating. This is obviously operating through a dev tunnel, but as you can see, it's reacting the same way. Okay. Same agent that I built, that I ported over, surfacing in two channels. Let's do a third. Let's bounce over here. Let's go to our Azure bot implementation and our Web Chat, and here is our third. Oh, there's our welcome message, too, in Seattle. Three channels. Four channels, counting the playground, running locally and remotely, debugging the same agent. This is the Agent SDK.

[ Applause ]

Okay. All right. I'm going to hand it back over to Sarah for just a minute, and then we're going to move on. And I'm going to show you some other cool stuff the Agent SDK does.

Sarah Critchley: That definitely did deserve a round of applause, right? Agents Playground. First of all, actually, you saw what it looked like without the SDK, without the Toolkit. Then you saw the amazing value that the Toolkit provides, and then you saw, let's just call it four

channels, right? That web client can essentially be like your website, right? You've got M365 Copilot. You've got Teams. Fantastic stuff. So I'm not going to talk about multi-agent that long, because we really just want to make this quite -- we want to show you the code. We want to show you this demos, but just touching on this super, super briefly and why multi-agent is so important to us. Because we recognize that our customers are working with multiple tech platforms. And then inside of that, you'll have teams of people working in different types of applications, whether that's Copilot Studio, whether that's Visual Studio. And we really want to be able to support all of these agents working together. So you can choose what's working best for you, what suits you as a developer or as a business user as well. And the SDK is super flexible. You heard in the intro how flexible we are. You bring your AI. You bring your orchestrator. You bring your knowledge. And because of this flexible nature, you can actually -- it's really your creativity, how you want to architect these multi-agent solutions. We see dispatcher broker quite a lot as a pattern. Because of this flexible nature of the Agents SDK, you can essentially then bring in other agents that can essentially, the main agent can dispatch to super easily. And you saw how fast that you can get the Agents SDK working in whatever channel you need. So enough from me. Let's see this in action, Matt.

Matt Barbour: Yep. Yeah, so just to be clear, by the word fast, that particular demo took me about 15 minutes to create. Okay. Starting with the Semantic Kernel and bringing some things over. Then it took me another 20 minutes of adding glitter to make it easier for folks to see and understand. Okay. If I'm not trying to make it so that my code is readable, it's about 15 minutes. Okay. All right. So I'm going to extend that demo that I just showed you real quick. I'm going to add a capability. I'm going to stop this. I'm going to add a capability to that demo. So I told you I was going to talk about the use streaming in a minute. Use streaming is a capability that was added to the Microsoft ecosystem in the fall of last year I believe is when it actually became available. And is a thing called streaming response. And streaming response allows us to be a little bit more interactive with our tech. So you saw, hey, I'm checking the forecast. I'm looking at the location. And then it was message, message, message, message, blah. In some of the Microsoft clients today, you've seen things where you'll see like a status bar pop up. I'm doing this. I'm working on this. And then the screen gets replaced with the content. Okay. That's done using a technique called streaming response. So, again, that same agent, we're going to bootstrap that up again. We're going to go through those four different channels. In fact, actually, just for expediency, I'm going to skip the Playground. I'm going to bounce back out here to my Web Chat. So this is the lowest resolution channel. This is the bottom. It doesn't have a whole lot of features. It's just basically a text with some adaptive card. What is the weather in Seattle? Okay. I'll see if it can piece that apart. Now, here of course you're seeing the typing indicator. By the way, the typing behavior is actually a function of the Agent SDK. You can enable it and turn it on. Okay. So you saw what's the weather in Seattle, but you didn't see any of the status popping up. It just completed the request, but it gave you a typing indicator as things are happening. Let's uplevel that now. What's the weather in Seattle

now? And here, you're now having a status stream providing. All I did was switch from using send messages to use streaming response. The Agent SDK handled the upscale and the downscale. Oh, I'm talking to this lower-level resolution client. Turn that into this kind of stream. Oh, no, I'm talking to the higher-level client. Let me talk to that level stream, okay, and let me take advantage of those capabilities. Now, this also works back through into the Copilot chat. And, by the way, those of you that want to target this chat, specifically on the M365 cloud, I cannot stress strongly enough, use streaming responses. They are very, very, very brutal on timeout on this client. Okay. And you're going to find that as you work with different clients and bring your agents to those clients, each client has different requirements. Okay. In the case of this client, very, very brutal. It will give you an error message within 15 seconds if it doesn't hear back from the agent. So the moment you receive something, send an information, hey, I'm working, and it'll be happy. Okay. So, moving on. We're going to stop this. We're going to shift gears a little bit and talk a little bit more about multi-agent and the dispatcher concept. So here, we're going to open up a thing called the dispatcher. Now, again, we're building out on that basic concept. What we had there, what you just saw was one agent, Agent SDK hosting a Semantic Kernel thing, talking to OpenAI. That's all it was doing. Now you're going to see Semantic Kernel and Copilot Studio working together. Okay. From the Agent SDK. Where Copilot Studio is not aware of Semantic Kernel, and Semantic Kernel isn't aware of Copilot Studio. Semantic Kernel thinks it's just a tool at the end of the day. So we're going to start this up. Now, you're going to notice something straight away. I'm going to let this load up and load all the way. You're going to see this message in the Playground. The reason you're going to see this message is that this demonstration requires, requires user authorization. The reason it requires user authorization is that Copilot Studio's interface is authorized by user. This is how our connector ecosystem works. This allows you to be that user going all the way through into Copilot Studio and taking advantage of the goodness that is the Copilot Studio ecosystem. And the goodness that is the AI Foundry ecosystem. Okay. But to do that, we have to produce an Entra-compatible ID. So I'm going to jump straight out here to the Teams client. Actually, I'll start here. Notice I haven't changed, by the way. I haven't actually changed the client I'm using. I'm still using Agent Builder every time. Okay. So here I'm going to say -- well, let's actually bring this up so you can see this over here. There we go. What is, same question. So now, instead of going out to the OpenWeather API, this is actually going out to Copilot Studio. And Copilot Studio has a adapter. It's one of the default samples, File, New, hey, go create a weather agent that works inside Copilot Studio. And in this case, the Agent SDK received the request. It went to Semantic Kernel. Semantic Kernel handed that to OpenAI. OpenAI handed back a plan that said, go call this tool. That tool happened to be Copilot Studio. The Agent SDK intercepted that request and said, oh, you need a user scope token for that. So let me go get that user scope token for you. And then sent it on. Okay. And I'll prove that to you in just a minute. So in this case, I'm just going to go ahead and say, get the forecast for today and send it on. And off it goes. And it's going to think about it. You can actually see in our diagnostics we have a little utility that gives our diagnostic for talking to Copilot Studio. And it tells me all the events and capabilities. Now, let me prove that to you.

Let me open up our dispatcher. I'm going to go to our MCS agents. This is the code that we have that's running to our MCS agent here. I'm going to come up here to this access token right here. The code that does this is this code right here. User authorization exchange turn token. So for every operation, every route that you can register, you can register one or more authorization handlers. Those authorization handlers in turn say that in order for you to process this request, the upstream client has to have provided the necessary scoped credentials for this. So before it ever comes to you, the credentials have been acquired. The user has gone through that process. In the case of Teams and the case of CBA, with SSO, the user never sees this. Or they see it and it's an authorize button. And they click an authorize button to authorize their scope. So if I now ask that same question again here. And actually I'll go over to Teams and do it. And we'll hit the breakpoint right here. And you can see, I'm going to take a step over that breakpoint. Let's minimize that. One of the awesome cool features of Visual Studio, by the way, is this. It does a token decode for you right here. And here you can see that I have a scope token for the API Power Platform. It has the appropriate invoke scope, Copilot Studio Invoke, and it's for me. So it's now communicating to Copilot Studio as me. The agent is not running under a user account. It's running under a system, running under a local system account. It exchanged that token, and I, who am using Teams, am now communicating with Copilot Studio. Straight passthrough. It's part of the underlying infrastructure that we provide in the Agent SDK. We don't want you to have to deal with this crap anymore. Okay (applause). I cannot tell you how much we've invested in making that work.

Sarah Critchley: Did you just make auth easy, Matt?

[ Laughter ]

Matt Barbour: All right. So let me do one more thing, and I'm going to show you one other thing. Now, how do we actually talk to Copilot Studio? When we talk to Copilot Studio, we registered those configurations in our app settings. So here we go. This is actually how we define Copilot Studio configurations in the extension that we have for the Agent SDK. Essentially, we defined the name of the thing, the thing we want to call it, the alias of the thing, because the alias allows us to do at notation. I can just at the alias right from my client, whatever client it happens to be. It does not depend on the client technology. And in turn route that request over to the appropriate environment, the appropriate agent. Now, yesterday, those of you that were in the session that saw me use the full URL, the connection string, that works here too. It's just if you happen to be switching between environments or you happen to be switching between scopes -- excuse me, environments, the scope may change. And the scope is automatically generated based on the environment connection that you're connecting to, which is facilitated by this. So in this case, you can see I have two of them registered. If I pop back over here, and in this case, I'm going to do at. I think CPX is what we called it, CPX. What can you do? And if I pop this back open here, you can see that, again, we've token exchanged, and now we're talking to a different agent. And it is communicating with that agent to get some information from

Copilot Studio. Now, we're taking a bit of a chance here because I didn't actually boot this agent up in the morning, so it's cold starting that Copilot Studio agent and talking to it to bring it in. You can see that it exchanged the conversation ID and brought it through. The one thing I want to draw your attention to is that this environment is a default environment. Oh, there it goes. This environment is the default environment. This environment is a different environment. As long as that agent is shared with me, my user identity, my authorization lets me into that agent, I can talk to it, and that's a feature of Copilot Studio and of Azure AI Foundry, too. It doesn't require an anonymous access or an escalation of privileges to do it. All right. I know I'm out of time, and I'm getting the death stare, so okay. Moving on. I'm going to go ahead and hand it back over to Sarah.

Sarah Critchley: Awesome. Thanks, Matt.

Matt Barbour: And let it go from there.

Sarah Critchley: Yeah, let's do that.

[ Applause ]

You saw streaming. You saw multi-agent. You saw auth. This is all of the value the Agents SDK provides. Now, we're going to shift gears a little bit. We've been talking about creating your agent, deploying it to a channel like Microsoft Teams or Microsoft 365 Copilot. We're going to flip this a little bit and actually now talk about the Microsoft 365 Copilot APIs. So one of the things that we really understand for developers is you want to be able to build compliant applications. Of course. You want to be able to embed Copilot experiences inside of your agent wherever your agent is. You want to ground your requests on semantically indexed data that lives inside of M365, and you also want to be able to analyze or optimize your M365 Copilot experience. Well, how could you do that with the Copilot APIs or the Microsoft 365 Copilot APIs? I see lots of -- go ahead. Take the pictures. I'll linger on this slide a little bit. There's four APIs that I just want to talk about. There's a blog article as well that goes into a bit more depth. So the first one is the Retrieval API. This is the API that you can use, that you can go ahead and actually get grounded data from M365. I'm going to double-click on this in a short while. You've got the Chat API, which can essentially be understood as a completion API. Do you want to essentially be able to access and use M365 Copilot without the UI? This is the API that you would use. Do you want to go ahead and essentially use that inside of your agent that lives inside a native application somewhere? Use that API. You've also got the Meeting Insights API, which is a fascinating API. This allows you, for anyone that's used M365 Copilot with Teams, once a Teams' meeting is finished, you get loads of insights. Who's been talking the most, action items, summaries. This data is readily available from this API without you having to read the transcription and get that data and make your own endpoint call. (Laughs) we've also got the -- that's a popular one, right? We've also got the Interactions Export API. So you can go ahead and essentially get interactions that have been made through Copilot like user

prompts, usage data, and you can, again, build applications on that data. So these are all amazing features, but we want to just double-click a little bit in the Retrieval API today. And so the reason why this is really important is because you kind of heard at the very beginning when I was giving you the examples of me interacting with my banking app and how important grounding your requests is and grounding it on relevant data that makes the response relevant to me, relevant to you. This is something that the Retrieval API does very, very well. It allows you to ground on your M365 data without taking your data out of M365. And we're going to show it to you today. Take everything you've just heard in the last 30 minutes or so and actually bring it together with the Retrieval API, and we're going to show you how it works.

Matt Barbour: Yep. So, as promised, this one, this demo you're going to see, specifically these API calls, are in private preview. These are not publicly available as of yet. And I'm going to look at you guys and say it's not necessarily stable. So you guys are seeing some live code here, live service. Cross your fingers. We'll get all the way through it, and it'll work properly. If not, we'll get an exercise in debugging. Okay. So I'm going to go ahead and bring my screen back here. All right. So, again, the philosophy is the same. This is an agent called Retrieval Agent. Again, it's using Semantic Kernel. And you're going to hear that a lot from my team specifically when we're talking about.NET and when we're talking about Python because Semantic Kernel is our product. When you hear us talking about JavaScript, you'll probably hear us talk about LangChain or other things of that nature because we don't yet have one for JavaScript. Give us time. In the short term, though, you're going to hear a lot about Semantic Kernel. The thing I want to keep stressing, though, is that you can do this with anything. You don't need to use Semantic Kernel. In fact, if you just want to call the API services and interact with them natively, you can do that, too. If you want to use the AI Foundry Project API and turn the whole orchestrator over to them, you can do that. Okay? I want to make sure you guys are clear on that. Now, in this particular example, this, again, is a Semantic Kernel plugin that I'm highlighting here. It is the build and retrieve plugin. And the build and retrieve plugin, when Semantic Kernel decides to call it, is going to get called with a user query, and it's going to use user authorization again. So user authorization in this case is using a thing called get turn token. In the last demo, you saw user authorization exchange. There's two philosophies that we use within user authorization. When you set up an agent registration in the Azure Bot Service, you can define multiple OAuth handlers. OAuth handlers can be scoped. So you can create a handler called foo that has a specific scope. You can create a handler called bar that has the API scope. An API scope is an exchangeable scope. You can't actually use it to talk to anything. You always have to exchange it for something. But if I create a scoped token, i.e., when the user logs in, that scoped token can be used directly. I can instruct this agent, when I invoked that particular handler, to pick up the scoped token. And, again, same process. If I have not authenticated for that token from me, it will ask me to authenticate for that token. Okay? It'll present me the appropriate things. Why would you use this versus the other? When you create an API tok

has. Most of the time that scares the pants off an end user because it's a list about yea long. When you, in turn, say, oh, no, I just need to talk to graph read and you use a scoped token, they're presented with a consent dialog that says they want to be able to read your profile. Much less threatening. Okay? So think about that as you design those sorts of interfaces. Okay. So I'm going to go ahead and invoke this. I'm going to put a breakpoint right here. We're going to see it work. I'm confident on everything up to this point. So, all right. Agent is up and running. We're going to pop open the dialog there so we can see it there on the left. Pin it off over there. We're going to pop over here to -- again, we're going to use Teams in this case. I'm going to say, what are the sessions at Build? That's the first question I'm going to ask. Okay. So this agent has been configured to say, hey, if I've got to talk to Build, if I'm asking questions about Build, include documentation from the retrieval endpoint. Okay. So first thing we do when we walk in here, we grab our access token. So I'm going to go take a look at our access token. And, again, notice I haven't changed my agent. I'm still using the agent client, so I have the same registration. At this point, I'm just asking for the Graph permission and not the other permissions. And here you can see that I've got the audience for Graph. Anyone who's worked with Graph for any length of time knows 003 is Graph. And then down here at the bottom, if I scroll down, those are my scopes that I'm requesting for. So that's what I had to consent to. And, again, it's me. So any licenses or requirements that are satisfied by my access are satisfied when I communicate to Graph. Okay. You need a Graph token to be able to talk to the retrieval APIs. So we're going to step through this process. And we're going to come down here to this. Now, you're going to see that, oh, I'm ignoring obsoletes whatnot. This API is changing, like, daily. This is why I'm not 100% confident that it is going to work for us this particular turn. This particular drop came to me last night. Okay. It worked great earlier. So we're going to step over it. And what's now happened -- oh, we're done. What's now happened is we communicated out to Graph using the Retrieval API, the private preview version Retrieval API, which targeted this SharePoint site and that document, any documents in those folders, to use to provide grounding data back to the next turn of the orchestrator. Okay. Your data in Graph being presented back. That is the retrieval API. And it can be scoped. You're not having to open up your SharePoint site to the entirety of the population. You can target specific documents or specific folders of documents or groups of folders of documents in that retrieval. We're going to go ahead and click "Continue." And we're going to see -- yep. And in this case, we took too long to respond. This is another thing. When working with the Retrieval API, Teams has limits. And at some point, Teams will decide that you've exceeded the amount of time allowed to because you were too busy talking and looking at your debug dump. So you're out of here. So we're going to go ahead and click "Continue." We're going to ask the same question again. And this time I'm not going to break on the debug. What are the sessions at Build? And maybe it will still break because I don't think I removed the breakpoint. Or did I? Oh, I stopped the bot. Hold on a second. Let me restart it. Operator error. There we are. And here. What are the sessions at Build? Okay. Working on it. Let me get rid of that breakpoint. And continue. Hit the actual "Continue" button. So now you're going to see the status. Now, again, this comes back to the behavior that you have to compensate for, specifically

dealing with custom engine agents in this chat, or in M365 chat. You need to provide status. You have to constantly poke it and tell it that something is happening. So what's happening here is the Semantic Kernel is iterating through, trying to decide what it wants to do. Let's take a look here. As you can see, that agent is cranking along. This is one of the challenges that I was dealing with, with the update from this morning. It gets it into what I call a death spiral, where the Semantic Kernel never really decides. The OpenAI model and the Semantic Kernel never decide that it's done. So it gets itself into a death spiral, and you end up with something like this. Okay. In-flight preview. This is why I said this is in-flight preview. This is going to get cleaned up. It will work. It will work properly. A lot of our preview customers who are using it have really good results with it in isolation, okay, and then are feeding it back in. But with all the changes that you guys have been seeing in Foundry, plus all the changes that's happening with Retrieval API, these two things aren't quite meshing just yet. Give us another week, another week and a half. Let's try it one more time. See if it gets all the way through. Okay. So we're spinning through, spinning, spinning, spinning. Yep. We're going to go into that spin again, and it may come out of it this time. It may not. But you will see it in turn come back and give us an answer one way or the other here in just a second. Okay. In this case, this is -- oh, there we go. We've got data that came back this time. So --

[ Applause ]

-- soon. This is why the Retrieval API is in private preview. Private preview, that means that we're still working on it, and we're not quite in stabilization just yet. But this gives you an idea of what's coming. Okay. Really exciting stuff from the team over there. Okay. And I think that was all I had for that, and I'm going to hand it back over to Sarah.

Sarah Critchley: Awesome. Thanks, Matt. So those APIs that we talked about, like the Retrieval API, they're in various stages of private and public preview. There's some blogs that we can share, and we've also got the team at the front as well. So if you have any questions on that, please speak to us afterwards. So let's go to the customer and partner section of our session. And I'm really pleased to welcome on the stage Gaurave and Renil. They're from KPMG, and they're going to talk about how they're maximizing revenue and client-facing tax applications using the Microsoft 365 Agents SDK.

[ Applause ]

Gaurave Sehgal: Can you guys hear me? All right. Okay. So, before we introduce ourselves, I have two quick questions for the audience. Who here likes to pay taxes? Well, one person. Yeah (laughs). Okay. So, yeah, it hurts, right, to pay taxes, hard-earned money. Well, okay. Who likes to prepare taxes, prepare for filing taxes? Yeah. Yeah, it hurts even more, right? So, my name is Gaurave Sehgal, and I'm a senior director with KPMG, a global tax function, and that's what we do. We help our clients, the biggest clients on the planet, help plan, prepare, and comply with tax laws and regulations, and that's our core job. In addition to

that, KPMG provides audit and advisory services to our clients also, and we are 125 years in business. We are proudly serving our clients throughout the globe, and we have 250 plus K employees working for us. Renil, do you want to introduce yourself?

Renil Abdulkader: Sure, thank you, Gaurave. I am Renil Abdulkader. I'm Engineering Director at KPMG. I lead the Identity and Access Management Practice for our global tax and legal services. Our job at KPMG, it's not that boring, actually. We translate the tax codes into reliable, maintainable application code.

Gaurave Sehgal: Yeah. So that brings us to the next topic here, which is we call Digital Gateway. This is our one-stop shop platform, which we have created to serve our clients. This is how we provide all our tax services to our clients globally, and the main thing which this platform has is what we call capabilities, such as workflows, document management, and the newest one is GenAI. Over GenAI, we have created lots of intelligent assets, such as personas, assistants, agents, and workflows, which our clients are using, which we are using internally to, again, prepare for those tax services or provide those tax services. One of the things we are going to show today is that -- so this platform is a web platform, but we want to open up other channels also for our clients. We want to meet them where they are, such as M365 or Teams environments.

Renil Abdulkader: So as Gaurave mentioned, over a century of deep domain expertise combined with the power of modern technology, we are not just keeping up. We are setting the pace, but the leadership only matters if we can continue to innovate. That's why we are focused on meeting our users directly where they are and bringing all these capabilities into their daily workflows. That basically means with the help of Agents SDK, now we can embed tax intelligence into the UI for AI, as Satya mentioned, the M365 Copilot, and the Teams. That basically, if you think about it, right, as Matt was mentioning, authenticating the users across hundreds, sometimes thousands of Entra ID tenants and bringing all this tax intelligence into their hands, providing secure access, continued governance, and seamless experience. So now let's jump into Digital Gateway. Let's jump into the demo. Okay, it's coming up. This is Digital Gateway, our unified platform for various capabilities that we have built into tax. You can see data analytics, workflows, legal entity management, relevant tax news. Let's look at the GenAI experience built into Digital Gateway. This is the current experience. We want to show you the current experience so we can compare and contrast when we move into the Teams experience.

Gaurave Sehgal: And we are secure. That's why that login screen again and again. I think it all timed out when laptop was connected.

Renil Abdulkader: Okay, goodness, the regulatory requirements of putting all the acceptable usage requirements. When you go to the GenAI chat interface, it looks like a regular chat interface. What is happening behind the scene is far from ordinary. Our tax professionals have built a library of personas that is catering to the needs of particular tax

requirements, real-world scenarios. And I will go and use this "Global Tax Incentive Researcher" for this demo. I think I clicked on it. Okay, it's coming. It's more a different resolution than I was used to, so help me on this one. You can see that the "Tax Incentive Researcher," our team has built this persona and added KPMG's thought leadership into this persona. When we are creating this persona, the tax professionals can attach documents directly from their laptop or connect to documents or data already in Digital Gateway and internal systems. By the way, a big shout out to all our tax professionals and technology team who have not only interpreted this regulatory complexities but also helped us make this deliver at scale.

Gaurave Sehgal: So this is KPMG's brain and the behavioral aspect which we have built into these personas, which our clients can use and utilize our services. Do you want to switch to Teams?

Renil Abdulkader: Okay, so let's give it a shot. In this one, a familiar question these days, we have manufacturing operations in China but R&D in US. What are the different tax incentives available to us in this scenario? It comes with this answer. Now, let's bring this same experience into the Teams. We will publish this into the Microsoft Marketplace, and also the companies can push that into their own Teams channels. Users can add it. Then we get Digital Gateway GenAI in Teams. Let's bring the personas that we have access in Digital Gateway into Teams. (Inaudible) so you can see it uses the same Global Tax Incentive Researcher. We'll get the same initial prompt that we have seen in Digital Gateway here as well. We will be using adaptive cards to do that one. This time, we'll ask a different question. Again, very interesting these days. That is, what's the different tax funds available in Mexico if you are doing automobile manufacturing in Mexico? So administrations change, governments change, tax policies change. It's not just optional for the tax teams to keep up to date with these tax regulations. It is almost always mandatory for these tax professionals in any organizations to keep up to date with the technology. So we've got relevant tax news, relevant personas built for all different tax scenarios in our system.

Gaurave Sehgal: I think we can skip to the code now.

Renil Abdulkader: I think the demo is not over unless we show the code.

[ Applause ]

So as Matt was mentioning, authentication is critical aspect of it. We are generating on behalf of token for the logged-in user. The user is logged into a tenant. Their own home tenant can talk to tax services in KPMG's tenant with single sign-on. The user will not even see what's happening. Once you add it, they can talk. And the heavy lifting is done by Digital Gateway, where we sent all this message to Digital Gateway and the response is sent back to Teams. And it even prints it in Markdown, so really good user experience for all our users. Thank you, everyone.

Gaurave Sehgal: That's all for the demo. Thank you. Back to Sarah.

[ Applause ]

Thank you. Thanks, Matt.

Sarah Critchley: That's pretty awesome, right? So let's wrap up. Got a couple minutes left. I just want to also shout out to Accenture. They're working really closely with us with the Microsoft 365 Agents SDK with their integrating agents in their AI Refinery in their trusted agent huddle, helping organizations really help build a network of agents that help with industry and interoperability. And also thank you so much to the Microsoft partner ecosystem, whether you're building with the Toolkit, SDK, APIs. Really, I understand how much dedication time that you need to really kind of just build with us. And this is really important to be able to get feedback and to be able to just understand is this meeting your use case. So really, really thank you to all of the partners that are working with us. Get started with the Toolkit and the SDK. That's the call to action. Really appreciate your time here today. You've got some AKA links. We've also got labs going on from 8:30 tomorrow. There's a survey there. If you want to give us some feedback, go try the Agents SDK at aka.ms/agents. There's the open hack that's ongoing. You can literally go build an agent with the Agents SDK, get real-time feedback from our very own product group. Our team are here, and they will be helping you as well if you have any questions. And there's also a competition going on for Build, which is can you build the best agent instructions as well. So you've got some links there. Thank you so much for choosing to spend your time here with us today.

Matt Barbour: You want to do some questions? We have a couple. We have like a minute.

Sarah Critchley: One minute 20 for questions.

Matt Barbour: We can take one question. No questions?

Sarah Critchley: No questions?

Matt Barbour: Oh, wait, there we go.

Speaker 1: If no one else is going to go, I'm going to take the question.

Matt Barbour: Take the question. Go for it.

Speaker 1: Did I miss the step where you deployed your code into the (inaudible)?

Sarah Critchley: So just for the audio recording, so the question was, did I miss something? Did you deploy two teams on M365 Copilot?

Matt Barbour: That's a great question. The answer is, is I didn't show you deployment. I ran everything off my laptop right here. Literally everything ran off my laptop. The only thing that

was actually deployed into the cloud was an Azure Bot Service registration and a manifest. That's it. Everything was running locally on my machine. If you want to deploy, the Agent Toolkit has a fantastic little automation feature to do the deployment and build everything for you, set up an app service, roll it up as a container. But that wasn't really the purpose of this particular presentation. But yeah. Yeah. Good catch. Yeah. But that's why I kept saying I'm using the same agent because all I'm doing is repointing that endpoint to the particular agent running on my machine that I needed to work with. Okay?

Sarah Critchley: Awesome.

Matt Barbour: All right.

Sarah Critchley: Thank you everyone.

Matt Barbour: Thank you very much.

END